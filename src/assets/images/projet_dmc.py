# -*- coding: utf-8 -*-
"""Projet_DMC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rh8D38NNpqpxmF1rqHTH9Y3ngkYyQO0J

# Analyse de besoins avec BERT

**Présentation du groupe** : Membres et filières

* DIALLO Djemilatou - EQUADE
* KAKOU GOLY Jean - DARM
* TIMITE Abdoul - EQUADE

## Contexte

Le **CFPB** (Consumer Financial Protection Bureau) est une agence gouvernementale américaine qui a pour but de protéger les consommateurs des pratiques déloyales dont ils peuvent être victime de la part des institutions financières.

Chaque semaine, le **CFPB** recolte des centaines de réclamations et les envoie aux entreprises financières concernées afin d'obtenir une réponse pour les consommateurs. Ces réclamations viennent alimenter l'historique des réclamations et cette base de données (**Consumer Complaint Database**) est gérée et mise à dipsosition par le Bureau via son site internet.

Nous voulons, à partir d'un echantillon de cette base de données, prédire le problème associé à une réclamation à partir de sa description en utilisant le modèle BERT. L'objectif est de fournir un outil capable d'identifier rapidement et précisément les problèmes, améliorant ainsi la réactivité et la qualité du service client.

## Démarche

**Déroulé du projet**

1. Manipulation des données
* Importation
* Exploration
* Prétraitement


2. Analyse de sentiment

3. Classification avec BERT


**Les variables à considérer dans la base :**

Consumer complaint narrative = entrée

Issue = etiquette

## Mise en oeuvre
"""

!pip install sentence_transformers
!pip install gensim
!pip install gdown

import transformers
import torch
from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup, BertForSequenceClassification
from torch.optim import AdamW
from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset
from torch.optim import AdamW
import numpy as np
import pandas as pd
import gdown
import seaborn as sns
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from collections import defaultdict
from textwrap import wrap
from torch import nn, optim
import pandas as pd
import numpy as np
from scipy import spatial
import os
import matplotlib
import matplotlib.pyplot as plt
import spacy
from spacy.lang.en import English
import en_core_web_sm
import multiprocessing
import gensim
from gensim.models import Word2Vec
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.cluster import contingency_matrix
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from mlxtend.plotting import plot_confusion_matrix
import plotly.express as px
import plotly.graph_objects as go
import re
from sentence_transformers import SentenceTransformer

"""### 1. Manipulation des données

Nous passons par Google Drive pour importer la base de données.
"""

file_id = "1mqaJzAeyhxPF6YRzP6oNIPI3YcK-nZSP"
url = f"https://drive.google.com/uc?id={file_id}"

gdown.download(url, "base_reclamations.csv", quiet=False)

# Importation de la base de données
reclamations = pd.read_csv("base_reclamations.csv")
reclamations.head(10)

# Dimension de la base de données
reclamations.shape

"""Notre base de données est donc composée de 89 793 réclamations et 18 variables décrivant ces réclamations."""

reclamations.info()

"""Nous observons que la majorité de nos variables ont des observations complètes, notamment les variables **Consumer complaint narrative** et **Issue** qui nous inttèresse. On peut neanmmoins remmarquer que la variable **Consumer disputed?** n'est pas renseigné.

Les variables étant majoritairement textuelles, elles sont de type *object*.
"""

import matplotlib.pyplot as plt
import missingno as msno
import seaborn as sns

# Valeurs manquantes
msno.matrix(reclamations)

"""Cette représentation nous permet de mieux visualiser l'ampleur des valeurs manquantes, que nous avions déjà identifié plus haut.

Les variables comportant des variables manquantes sont :
* Consumer disputed?, qui n'est pas renseigné
* Tags
* Company public response
* Sub-issue

Il faut savoir qu'il n'est pas courant que les entreprises à qui sont adressées des réclamations envoient des reponses dites publiques (que tout le monde peut connaitre). Le plus souvent les réclamations se règle en privée, d'où le fait que la variable ***Company public response*** comporte beaucoup de valeurs manquantes.
"""

reclamations.nunique()

"""Nous remarquons que plusieurs variables ont des valeurs uniques. Cela n'est cependant pas anormal. En effet, nous avons sélectionner les données récoltées dans l'Etat du **TEXAS**, ce qui fait que la variable ***State*** n'a qu'une valeur unique qui est "**TEXAS**". De même pour les variables sur le consentement et le moyen d'envoi des réclamations (***Consumer consent provided?*** et ***Submitted via***) : ce sont seulement les réclamations envoyées via le site du CPFB, sur lequel le consentement a été donné de les publier, qui figurent dans l'historique des réclamations gérées par le CPFB."""

reclamations.duplicated().sum()/len(reclamations)*100

"""Notre jeu de données ne comporte pas de ligne dupliquées, ce qui est une bonne nouvelle."""

def plot_categorical(data: pd.DataFrame, x: str, n: int):
    """
    Diagramme de comptage pour une variable catégorielle avec Plotly

    Parameters:
    -----------
    data: DataFrame
        La base de données

    x: str
        La variable catégorielle à représenter

    n: int
        Taille de la police pour l'affichage des modalités
    """

    # Compter les occurrences de chaque catégorie
    counts = data[x].value_counts().reset_index()
    counts.columns = [x, 'count']

    # Créer le graphique à barres
    fig = go.Figure(data=[
        go.Bar(x=counts[x], y=counts['count'], marker_color='blue')
    ])

    # Mettre à jour la mise en page
    fig.update_layout(
        xaxis=dict(tickangle=-45),
        font=dict(size=n),
        xaxis_title=x,
        yaxis_title='Count'
    )

    # Afficher le graphique
    fig.show()

#Exemple d'utilisation avec un DataFrame `reclamations` et une colonne catégorielle "Issue"
plot_categorical(reclamations, "Issue", 7)

"""La variable **Issue** comportent plusieurs types de description du problème. Nous remarquons cependant que la majorité des réclamations porte sur un petit nombre de problèmes spécifiques. Regardons les de plus près :"""

counts = reclamations['Issue'].value_counts()
top_counts = counts[:10]

if len(counts) > 10:
    other_count = counts[10:].sum()
    top_counts['Autres'] = other_count

# Création du graphique à secteurs avec Plotly
fig = go.Figure(data=[go.Pie(labels=top_counts.index, values=top_counts, hole=0.3)])

# Mise à jour de la mise en page du graphique
fig.update_layout(
    title_text='Répartition de la variable Issue',
    annotations=[dict(text='Issue', x=0.5, y=0.5, font_size=20, showarrow=False)]
)

# Affichage du graphique
fig.show()

"""On note donc que les principales préoccupations des utilisateurs (***Incorrect information on your report*** et ***Improper use of your report***) dans notre base de données, représentant plus de 50% des cas de réclamation, sont liées aux **credit reports**. C'est un historique de l'état des finances des individus et peut affecter la capacité à obtenir un crédit, un emploi ou une assurance.

Nous avons sélectionné aléatoirement un sous-ensemble de 5000 lignes dans notre ensemble de données initial, qui contient au total 89783 lignes. Cette réduction de taille nous permettra de travailler plus efficacement avec notre ensemble de données tout en conservant une représentation significative de nos données pour nos analyses et nos expériences.
"""

data_reclamations = reclamations.sample(n=5000, random_state=42)
data_reclamations.reset_index(drop=True, inplace=True)

# Les variables pertinentes
data_reclamations = data_reclamations[["Consumer complaint narrative","Issue"]]
data_reclamations.head(15)

"""Il est recommandé d'appliquer le nettoyage uniquement sur les variables d'entrées qui seront utilisée pour entrainer notre modèle. Par conséquent nous appliquerons le nettoyage sur les variables ***Consumer complaint narrative***, qui est la description de la réclamation, et ***Issue*** qui est le problème remonté dans la description et que nous utiliserons comme "Label" dans notre modèle."""

data_reclamations["Consumer complaint narrative"][3]

"""On peut voir que la description comporte plusieurs types de caractères, notamment des caractères spéciaux comme des paranthèses ou des tirets. Certains mots sont aussi en majuscules dans le texte et il y a des espaces supplémentaires entre d'autres mots.

Nous devons donc nettoyer notre base avant de passer à l'entraînement de notre modèle. Cela garantie que le modèle se concentre sur les informations pertinentes, réduit le risque de surapprentissage et améliore généralement les performances.
"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Téléchargements NLTK
nltk.download("punkt")
nltk.download("punkt_tab")
nltk.download("stopwords")

STOP_WORDS = set(stopwords.words("english"))

def clean_text(text):
    if not isinstance(text, str):
        return ""

    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()

    tokens = word_tokenize(text, language="english")
    tokens = [t for t in tokens if t not in STOP_WORDS]

    return " ".join(tokens)

"""Nous definissons une fonction **clean_texte** qui nous permet d'effectuer le nettoyage du texte et l'appliquons par la suite à toutes les colonnes de notre base de données."""

data_reclamations["Consumer complaint narrative"] = data_reclamations["Consumer complaint narrative"].fillna("").apply(clean_text)

data_reclamations["Consumer complaint narrative"][3]

"""Nous constatons maintenant que la description de la réclamation a été néttoyé des éléments spécifiés dans notre fonction **clean_text**."""

# Encoder les labels
data_reclamations['Issue_Category'], uniques = pd.factorize(data_reclamations['Issue'])
category_mapping = {index: label for index, label in enumerate(uniques)}

# Vérifiez le nombre de classes uniques et les étiquettes correspondantes
num_classes = len(np.unique(data_reclamations['Issue_Category']))
target_names = [category_mapping[i] for i in range(num_classes)]

"""Nous encodons la variable ***Issue*** qui nous servira de label. Puis nous vérifions que les catégories correspondent bien aux descriptions."""

# Text mining
from nltk.tokenize import word_tokenize
import nltk
import collections

all_desc = ' '.join([text for text in data_reclamations['Consumer complaint narrative']])
len(all_desc)

"""Nous allons regarder les mots les plus récurrents dans la description des réclamations. Pour cela, nous regroupons toutes les descriptions ensembles. Cela nous donne un texte de taille 60 407 767."""

nltk.download('punkt')
all_desc_1_gram = word_tokenize(all_desc, language="english")
all_desc_common = collections.Counter(all_desc_1_gram).most_common()
all_desc_common[0:30]

"""Dans cette liste des 30 premiers mots les plus récurrents, nous retrouvons les mots ***account*** ou ***accounts***, ***balance***, ***agency*** et ***debt*** qui relève du vocabulaire de la banque; ce qui est cohérent avec notre base de données. Nous avons également les mots ***15***, ***usc***, ***section*** et ***1681*** qui font référence au **Fair Credit Reporting Act** qui est une loi permettant aux consommateurs d'accéder à leurs rapports de crédit, de les corriger et de limiter leur utilisation. Enfin, le mot ***inaccurate***, sous entend que les réclamations les plus fréquentes sont liées à des problèmes d'inexactitude dans les rélévés financiers des consommateurs. Ce qui est cohérent avec la répartition de notre variable ***Issue*** vu plus haut.

### 2. Analyse de sentiment

Nous allons faire une analyse le sentiment des descriptions de réclamations en utilisant la fonction `get_sentiment`, puis crée des colonnes distinctes pour stocker la polarité et la subjectivité de chaque texte. Cela permet d'obtenir une vision plus détaillée de la nature des réclamations, en indiquant à quel point elles sont positives, négatives, objectives ou subjectives.
"""

# Charger un modèle Sentence Transformer pré-entraîné
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

from textblob import TextBlob
# Fonction pour obtenir le sentiment d'un texte
def get_sentiment(text):
    # Créer un objet TextBlob
    blob = TextBlob(text)
    # Obtenir le sentiment
    return blob.sentiment.polarity, blob.sentiment.subjectivity

# Appliquer la fonction de sentiment à la colonne des narratives
data_reclamations['sentiment'] = data_reclamations['Consumer complaint narrative'].apply(get_sentiment)

# Créer des colonnes séparées pour la polarité et la subjectivité
data_reclamations['polarity'] = data_reclamations['sentiment'].apply(lambda x: x[0])
data_reclamations['subjectivity'] = data_reclamations['sentiment'].apply(lambda x: x[1])

# Afficher les résultats
data_reclamations[['Consumer complaint narrative', 'polarity', 'subjectivity','sentiment']].head()

"""Pour chaque réclamations, nous avons calculer le sentiment c'est à dire la calcule la polarité (positivité ou négativité) et la subjectivité (objectivité ou subjectivité) du texte en utilisant la bibliothèque TextBlob."""

negative_polarity = data_reclamations[data_reclamations['polarity'] < 0]
print(negative_polarity)

def to_sentiment(rating):
    if rating < 0:
        return 0
    elif 0 <= rating < 0.12:
        return 1
    else:
        return 2

# Apply the to_sentiment function to the 'polarity' column
data_reclamations.loc[:, 'sentiment'] = data_reclamations.polarity.apply(to_sentiment)
class_names = ['negative', 'neutral', 'positive']

# Calculate the counts for each sentiment
sentiment_counts = data_reclamations['sentiment'].value_counts().sort_index()

# Define the colors for each sentiment
colors = ['red', 'blue', 'green']

# Create the bar chart with Plotly
fig = go.Figure(data=[
    go.Bar(
        x=class_names,
        y=sentiment_counts,
        marker_color=colors,
        text=sentiment_counts,
        textposition='auto'
    )
])

# Update layout for the plot
fig.update_layout(
    title='Distribution of Sentiments',
    xaxis_title='Sentiment',
    yaxis_title='Number of Complaints'
)

# Show the plot
fig.show()

"""Il y a :
- 1633 réclamations classées comme négatives.
- 1710 réclamations classées comme neutres.
- Il y a 1657 réclamations classées comme positives.

Ce graphique permet de visualiser la répartition des différents types de sentiments dans les réclamations des consommateurs. Les réclamations neutres sont les plus nombreuses avec 1710 occurrences.

Le fait que les réclamations neutres soient les plus nombreuses avec 1710 occurrences signifie que, parmi les réclamations analysées, la majorité n'exprime pas de sentiment fort ni positif ni négatif. Cela pourrait indiquer que de nombreux consommateurs décrivent simplement des faits ou des situations sans y ajouter de jugement émotionnel. En d'autres termes, ces réclamations se contentent de rapporter des problèmes ou des préoccupations de manière factuelle, sans exprimer une satisfaction particulière ou un mécontentement significatif.

### 3. Classification avec Bert

Nous allons maintenant passer à l'entraînement du modèle de prédiction. Nous utilisons pour cela le modèle BERT pré-entrainer à lequel nous rajoutons une couche pour la classification.

#### Tokenization et chargement du modèle

Nous commençons par préparer nos données en vue de leur utilisation avec le modèle BERT (Bidirectional Encoder Representations from Transformers). Pour cela nous allons tokenizer la description des réclamations (variable ***Consumer complaint narrative***) en utilisant la bibliothèque **transformers** de Hugging Face et **torch** de PyTorch.
"""

# Tokenizer BERT
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Encodage des textes
encodings = tokenizer(data_reclamations['Consumer complaint narrative'].tolist(), truncation=True, padding=True, max_length=256)

# Convertir les labels en tenseur
labels = torch.tensor(data_reclamations['Issue_Category'].tolist())

# Convertir les encodages en tenseurs
input_ids = torch.tensor(encodings['input_ids'])
attention_masks = torch.tensor(encodings['attention_mask'])

"""Nous divisons ensuite notre jeu de données en données d'entraînement et de validation."""

# Créer un DataLoader
dataset = TensorDataset(input_ids, attention_masks, labels)

# Diviser les données en ensembles d'entraînement et de validation
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)

"""Nous chargons maintenant le modèle Bert pré-entraîné pour faire de la classification de la bibliothèque **transformers** de Hugging Face. Nous définisons comme optimiseur **AdamW**, qui est une variante de l'algorithme d'optimisation Adam (elle inclut une correction pour la régularisation de type L2 : le **weight decay**) et un Scheduler (stratégie pour l'ajustement de la learning rate) de type linéaire."""

# Charger le modèle BERT
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)

# Définir l'optimiseur
optimizer = AdamW(model.parameters(), lr=2e-5)

# Scheduler
total_steps = len(train_dataloader) * 3
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

# Définir l'appareil
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

"""#### Le modèle : entraînement et validation

Nous définissons maintenant le modèle pour l'apprentissage. Nous créons une fonction ***train_epoch*** pour la phase d'entraînement et une fonction ***eval_model*** pour la phase de validation.
"""

# Fonction d'entraînement pour une epoch
def train_epoch(model, dataloader, optimizer, device, scheduler):
    model.train()
    total_loss = 0
    for batch in dataloader:
        batch = tuple(t.to(device) for t in batch)
        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}
        optimizer.zero_grad()
        outputs = model(**inputs)
        loss = outputs.loss
        total_loss += loss.item()
        loss.backward()
        optimizer.step()
        scheduler.step()
    return total_loss / len(dataloader)

# Fonction d'évaluation
def eval_model(model, dataloader, device):
    model.eval()
    predictions, true_labels = [], []
    with torch.no_grad():
        for batch in dataloader:
            batch = tuple(t.to(device) for t in batch)
            inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}
            outputs = model(**inputs)
            logits = outputs.logits
            predictions.append(logits.argmax(dim=-1).cpu().numpy())
            true_labels.append(batch[2].cpu().numpy())
    predictions = np.concatenate(predictions)
    true_labels = np.concatenate(true_labels)
    return accuracy_score(true_labels, predictions), classification_report(true_labels, predictions, target_names=target_names,labels=range(num_classes), zero_division=0)

"""Nous lançons l'entraînement et l'évaluation du modèle sur 3 epochs."""

# Entraînement et évaluation
epochs = 3
for epoch in range(epochs):
    train_loss = train_epoch(model, train_dataloader, optimizer, device, scheduler)
    val_accuracy, val_report = eval_model(model, val_dataloader, device)
    print(f"Epoch {epoch+1}/{epochs}")
    print(f"Train loss: {train_loss}")
    print(f"Validation accuracy: {val_accuracy}")
    print(f"Validation report:\n{val_report}")

"""Nous arrivons donc à 58% de précision avec notre modèle. Ce qui n'est pas vraiment optimale.

#### Prédiction du problème en fonction de la réclamation

Nous allons maintenant tester les performance de notre modèle sur une réclamation fictif.
"""

def predict_issues(model, tokenizer, texts, device):
    model.eval()
    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors='pt')
    input_ids = encodings['input_ids'].to(device)
    attention_masks = encodings['attention_mask'].to(device)

    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_masks)
        logits = outputs.logits
        predictions = logits.argmax(dim=-1).cpu().numpy()

    return predictions

"""Issue = Incorrect information on your report

Nous choisissons une réclamation au hasard pour tester notre modèle et nous remarquons qu'il prédit bien le problème à partir de la description de la réclamation.

"""

new_texts = ["Good day I have disputed a duplicate account with a collection company they only removed 1 account and left the other account of the same account number but everything is different. "]
predictions = predict_issues(model, tokenizer, new_texts, device)
predicted_labels = [target_names[p] for p in predictions]
print(predicted_labels)